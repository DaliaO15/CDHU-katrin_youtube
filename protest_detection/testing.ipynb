{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b29c008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca807341",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalLayer(nn.Module):\n",
    "    \"\"\"Modified last layer for resnet50 for your dataset\"\"\"\n",
    "    def __init__(self):\n",
    "        super(FinalLayer, self).__init__()\n",
    "        self.fc = nn.Linear(2048, 12)  # Assuming you have 12 output classes\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "def modified_resnet50():\n",
    "    # Load pretrained resnet50 with a modified last fully connected layer\n",
    "    model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "    model.fc = FinalLayer()\n",
    "    return model\n",
    "\n",
    "# Load the modified ResNet-50 model\n",
    "model = modified_resnet50()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "733fb955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready\n"
     ]
    }
   ],
   "source": [
    "# Load the protest prediction model\n",
    "model_checkpoint = torch.load('model_best.pth.tar')\n",
    "model.load_state_dict(model_checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print('Model ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d59cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to match the model's input size\n",
    "    transforms.ToTensor(),           # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d978be23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your input image\n",
    "imgpath = 'test_img/protest_image.jpg'\n",
    "image = Image.open(imgpath)  # Replace 'your_image.jpg' with the path to your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e767f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "input_tensor = preprocess(image)\n",
    "\n",
    "# Add a batch dimension (1 image)\n",
    "input_tensor = input_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f831c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move the model and input data to CUDA (if available)\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to('cuda')\n",
    "    input_tensor = input_tensor.to('cuda')\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "output = output.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e227fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise results \n",
    "\n",
    "columns = [\"imgpath\", \"protest\", \"violence\", \"sign\", \"photo\",\n",
    "                      \"fire\", \"police\", \"children\", \"group_20\", \"group_100\",\n",
    "                      \"flag\", \"night\", \"shouting\"]\n",
    "\n",
    "# Convert the output tensor to list\n",
    "output_list = output[0].tolist()\n",
    "\n",
    "# Create a DataFrame with the specified columns and populate it\n",
    "df = pd.DataFrame(columns=columns)\n",
    "df.loc[0] = [imgpath] + output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19af299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>protest</th>\n",
       "      <th>violence</th>\n",
       "      <th>sign</th>\n",
       "      <th>photo</th>\n",
       "      <th>fire</th>\n",
       "      <th>police</th>\n",
       "      <th>children</th>\n",
       "      <th>group_20</th>\n",
       "      <th>group_100</th>\n",
       "      <th>flag</th>\n",
       "      <th>night</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_img/protest_image.jpg</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.47094</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>0.778701</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.016833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      imgpath   protest  violence      sign     photo   \n",
       "0  test_img/protest_image.jpg  0.999451   0.47094  0.999498  0.021265  \\\n",
       "\n",
       "       fire    police  children  group_20  group_100      flag     night   \n",
       "0  0.000436  0.003768  0.006847  0.979061   0.778701  0.044016  0.109219  \\\n",
       "\n",
       "   shouting  \n",
       "0  0.016833  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e139364",
   "metadata": {},
   "source": [
    "#### One more image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be67b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your input image\n",
    "imgpath2 = 'test_img/concert_img.jpg'\n",
    "image2 = Image.open(imgpath2)  # Replace 'your_image.jpg' with the path to your image\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor2 = preprocess(image2)\n",
    "\n",
    "# Add a batch dimension (1 image)\n",
    "input_tensor2 = input_tensor2.unsqueeze(0)\n",
    "input_tensor2 = input_tensor2.to('cuda')\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output2 = model(input_tensor2)\n",
    "\n",
    "output2 = output2.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cf7c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the output tensor to list\n",
    "output_list2 = output2[0].tolist()\n",
    "\n",
    "# Create a DataFrame with the specified columns and populate it\n",
    "df.loc[1] = [imgpath2] + output_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d0ecbda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>protest</th>\n",
       "      <th>violence</th>\n",
       "      <th>sign</th>\n",
       "      <th>photo</th>\n",
       "      <th>fire</th>\n",
       "      <th>police</th>\n",
       "      <th>children</th>\n",
       "      <th>group_20</th>\n",
       "      <th>group_100</th>\n",
       "      <th>flag</th>\n",
       "      <th>night</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_img/protest_image.jpg</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.470940</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>0.778701</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.016833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_img/concert_img.jpg</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>0.579759</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.979577</td>\n",
       "      <td>0.543736</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      imgpath   protest  violence      sign     photo   \n",
       "0  test_img/protest_image.jpg  0.999451  0.470940  0.999498  0.021265  \\\n",
       "1    test_img/concert_img.jpg  0.046097  0.384434  0.579759  0.007577   \n",
       "\n",
       "       fire    police  children  group_20  group_100      flag     night   \n",
       "0  0.000436  0.003768  0.006847  0.979061   0.778701  0.044016  0.109219  \\\n",
       "1  0.016681  0.010498  0.001537  0.979577   0.543736  0.035417  0.019279   \n",
       "\n",
       "   shouting  \n",
       "0  0.016833  \n",
       "1  0.006837  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5049f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your input image\n",
    "imgpath3 = 'test_img/bonfire.jpg'\n",
    "image3 = Image.open(imgpath3)  # Replace 'your_image.jpg' with the path to your image\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor3 = preprocess(image3)\n",
    "\n",
    "# Add a batch dimension (1 image)\n",
    "input_tensor3 = input_tensor3.unsqueeze(0)\n",
    "input_tensor3 = input_tensor3.to('cuda')\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output3 = model(input_tensor3)\n",
    "\n",
    "output3 = output3.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3187327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the output tensor to list\n",
    "output_list3 = output3[0].tolist()\n",
    "\n",
    "# Create a DataFrame with the specified columns and populate it\n",
    "df.loc[2] = [imgpath3] + output_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b1cc77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>protest</th>\n",
       "      <th>violence</th>\n",
       "      <th>sign</th>\n",
       "      <th>photo</th>\n",
       "      <th>fire</th>\n",
       "      <th>police</th>\n",
       "      <th>children</th>\n",
       "      <th>group_20</th>\n",
       "      <th>group_100</th>\n",
       "      <th>flag</th>\n",
       "      <th>night</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_img/protest_image.jpg</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.470940</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>0.778701</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.016833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_img/concert_img.jpg</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>0.579759</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.979577</td>\n",
       "      <td>0.543736</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_img/bonfire.jpg</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.393090</td>\n",
       "      <td>0.663169</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.646179</td>\n",
       "      <td>0.175210</td>\n",
       "      <td>0.149234</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>0.031960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      imgpath   protest  violence      sign     photo   \n",
       "0  test_img/protest_image.jpg  0.999451  0.470940  0.999498  0.021265  \\\n",
       "1    test_img/concert_img.jpg  0.046097  0.384434  0.579759  0.007577   \n",
       "2        test_img/bonfire.jpg  0.013813  0.393090  0.663169  0.014661   \n",
       "\n",
       "       fire    police  children  group_20  group_100      flag     night   \n",
       "0  0.000436  0.003768  0.006847  0.979061   0.778701  0.044016  0.109219  \\\n",
       "1  0.016681  0.010498  0.001537  0.979577   0.543736  0.035417  0.019279   \n",
       "2  0.049050  0.032035  0.005591  0.646179   0.175210  0.149234  0.440524   \n",
       "\n",
       "   shouting  \n",
       "0  0.016833  \n",
       "1  0.006837  \n",
       "2  0.031960  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08a3bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your input image\n",
    "imgpath4 = 'test_img/crowd_walking.jpg'\n",
    "image4 = Image.open(imgpath4)  # Replace 'your_image.jpg' with the path to your image\n",
    "\n",
    "# Preprocess the image\n",
    "input_tensor4 = preprocess(image4)\n",
    "\n",
    "# Add a batch dimension (1 image)\n",
    "input_tensor4 = input_tensor4.unsqueeze(0)\n",
    "input_tensor4 = input_tensor4.to('cuda')\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    output4 = model(input_tensor4)\n",
    "\n",
    "output4 = output4.to('cpu')\n",
    "\n",
    "# Convert the output tensor to list\n",
    "output_list4 = output4[0].tolist()\n",
    "\n",
    "# Create a DataFrame with the specified columns and populate it\n",
    "df.loc[23] = [imgpath4] + output_list4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7bfe4fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imgpath</th>\n",
       "      <th>protest</th>\n",
       "      <th>violence</th>\n",
       "      <th>sign</th>\n",
       "      <th>photo</th>\n",
       "      <th>fire</th>\n",
       "      <th>police</th>\n",
       "      <th>children</th>\n",
       "      <th>group_20</th>\n",
       "      <th>group_100</th>\n",
       "      <th>flag</th>\n",
       "      <th>night</th>\n",
       "      <th>shouting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_img/protest_image.jpg</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.470940</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.003768</td>\n",
       "      <td>0.006847</td>\n",
       "      <td>0.979061</td>\n",
       "      <td>0.778701</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.109219</td>\n",
       "      <td>0.016833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_img/concert_img.jpg</td>\n",
       "      <td>0.046097</td>\n",
       "      <td>0.384434</td>\n",
       "      <td>0.579759</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.979577</td>\n",
       "      <td>0.543736</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.019279</td>\n",
       "      <td>0.006837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_img/bonfire.jpg</td>\n",
       "      <td>0.013813</td>\n",
       "      <td>0.393090</td>\n",
       "      <td>0.663169</td>\n",
       "      <td>0.014661</td>\n",
       "      <td>0.049050</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.646179</td>\n",
       "      <td>0.175210</td>\n",
       "      <td>0.149234</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>0.031960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_img/crowd_walking.jpg</td>\n",
       "      <td>0.267595</td>\n",
       "      <td>0.501311</td>\n",
       "      <td>0.182358</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.180212</td>\n",
       "      <td>0.055304</td>\n",
       "      <td>0.006301</td>\n",
       "      <td>0.951225</td>\n",
       "      <td>0.395506</td>\n",
       "      <td>0.031207</td>\n",
       "      <td>0.007318</td>\n",
       "      <td>0.006282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       imgpath   protest  violence      sign     photo   \n",
       "0   test_img/protest_image.jpg  0.999451  0.470940  0.999498  0.021265  \\\n",
       "1     test_img/concert_img.jpg  0.046097  0.384434  0.579759  0.007577   \n",
       "2         test_img/bonfire.jpg  0.013813  0.393090  0.663169  0.014661   \n",
       "23  test_img/crowd_walking.jpg  0.267595  0.501311  0.182358  0.002850   \n",
       "\n",
       "        fire    police  children  group_20  group_100      flag     night   \n",
       "0   0.000436  0.003768  0.006847  0.979061   0.778701  0.044016  0.109219  \\\n",
       "1   0.016681  0.010498  0.001537  0.979577   0.543736  0.035417  0.019279   \n",
       "2   0.049050  0.032035  0.005591  0.646179   0.175210  0.149234  0.440524   \n",
       "23  0.180212  0.055304  0.006301  0.951225   0.395506  0.031207  0.007318   \n",
       "\n",
       "    shouting  \n",
       "0   0.016833  \n",
       "1   0.006837  \n",
       "2   0.031960  \n",
       "23  0.006282  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31b0d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo5_transf_learn_env",
   "language": "python",
   "name": "yolo5_transf_learn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
